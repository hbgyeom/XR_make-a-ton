import parselmouth
import numpy as np
import matplotlib.pyplot as plt
from gtts import gTTS
from PIL import Image, ImageEnhance

"""
plot 납작하게 만들기 그리고 두개마다 저장하기 
plt.subplot() -> subplot(2,1,figsize=(10,2))

title을 original pitch만 남기고 나머지는 전부 공백 f"    "

plt.savefig에서 box tight 지우기, title이 잘리는 이슈

그래프 y축 제목을 90도 돌려서 달았음 
plt.ylabel('Pitch', rotation=0, labelpad=20)
plt.ylabel('Intensity', rotation=0, labelpad=20)
폰트 사이즈 추가

글자 사이에 공백을 추가해서 단어로 나누어지도록 하기
,가 있으면 공백이 많이 생김. 콤마가 두개 있는 경우는 예외 처리하고 
하나 있으면 콤마 기준으로 두 덩이로 나누고 
없으면 단어를 균등 분포 시키기기
맨앞에 space list 추가했음
문장별로 달라지는데 이게 최선인듯

pitch더 잘 확인할 수 있게 ylim을 좀더 tight하게 바꿨음
"""

space2 = " "*80
space3 = ' '*40
space4 = ' '*30
space5 = ' '*22
space6 = ' '*19
space7 = ' '*20
space = [space2, space3, space4, space5, space6, space7]

# target = "C:/Users/HBG/codes/tp/F/F03/Session3/wav_arrayMic/0052.wav"
#target = "shedoesntlikeittohave.wav"
target = "thiswaseasyforus.wav"
text = "She runs every morning"
text = "hi, how are you"
text = "It is a beautiful day."
text = "I love programming"
text = "hi hello"
text = "hi how are you"
text = "she doesn't like it to have"
text = "this was easy for us"
text = "She runs every morning twice"
text = "This was easy for us."
#text = "she doesn't like it to have"


def short_seg(times, freq, threshold):
    filtered_times = []
    filtered_freq = []
    current_segment_times = []
    current_segment_freq = []

    for i in range(len(freq)):
        if freq[i] != 0:
            # Add to current non-zero segment
            current_segment_times.append(times[i])
            current_segment_freq.append(freq[i])
        else:
            # If zero is encountered, check the current segment length
            if len(current_segment_freq) >= threshold:
                # Keep the segment if it meets the length threshold
                filtered_times.extend(current_segment_times)
                filtered_freq.extend(current_segment_freq)
            # Add the zero value and reset the current segment
            filtered_times.append(times[i])
            filtered_freq.append(freq[i])
            current_segment_times = []
            current_segment_freq = []

    # Handle the last segment if it was non-zero
    if len(current_segment_freq) >= threshold:
        filtered_times.extend(current_segment_times)
        filtered_freq.extend(current_segment_freq)

    return np.array(filtered_times), np.array(filtered_freq)


def high_seg(times, freq):
    mean_freq = np.mean(freq)
    std_freq = np.std(freq)

    filtered_freq = np.where(freq > mean_freq + 2 * std_freq, 0, freq)
    return np.array(times), np.array(filtered_freq)


og_voice = parselmouth.Sound(target)

og_pitch = og_voice.to_pitch()
og_times = og_pitch.xs()
temp = len(og_times)
og_freq = og_pitch.selected_array['frequency']


og_times, og_freq = high_seg(og_times, og_freq)
og_times, og_freq = short_seg(og_times, og_freq, 10)
length = temp - len(og_times)

nz_indices_og = np.nonzero(og_freq)[0]
if nz_indices_og.size > 0:
    start_og, end_og = nz_indices_og[0], nz_indices_og[-1] + 1
    og_times = og_times[start_og:end_og]
    og_freq = og_freq[start_og:end_og]

# len(og_intensity.xs()) - (end_og - len(og_times))##################################################################
og_intensity = og_voice.to_intensity()
og_intensity_times = og_intensity.xs()
length = len(og_intensity_times)
og_intensity_times = og_intensity_times[length*start_og//temp:length*end_og//temp]
og_intensity_values = og_intensity.values.T
og_intensity_values = og_intensity_values[length*start_og//temp:length*end_og//temp]

tts = gTTS(text=text, lang="en")
tts.save("audio.mp3")

tts_voice = parselmouth.Sound("audio.mp3")

tts_pitch = tts_voice.to_pitch()
tts_times = tts_pitch.xs()
tts_freq = tts_pitch.selected_array['frequency']

tts_times, tts_freq = high_seg(tts_times, tts_freq)
tts_times, tts_freq = short_seg(tts_times, tts_freq, 10)

nz_indices_tts = np.nonzero(tts_freq)[0]
if nz_indices_tts.size > 0:
    start_tts, end_tts = nz_indices_tts[0], nz_indices_tts[-1] + 1
    tts_times = tts_times[start_tts:end_tts]
    tts_freq = tts_freq[start_tts:end_tts]

tts_intensity = tts_voice.to_intensity()
tts_intensity_times = tts_intensity.xs()
# tts_intensity_times = tts_intensity_times[start_tts:end_tts]
tts_intensity_values = tts_intensity.values.T
tts_intensity_values = tts_intensity_values * 1.3
# tts_intensity_values = tts_intensity_values[start_tts:end_tts]

pitch_return = [og_times, og_freq, tts_times, tts_freq]
intensity_return = [og_intensity_times, og_intensity_values,
                    tts_intensity_times, tts_intensity_values]

fig1, ax1 = plt.subplots(2,1,figsize=(10,4))
ax1[0].set_ylabel('Pitch  ', rotation=0, labelpad=22, fontsize=20)
plt.ylabel('Intensity', rotation=0, labelpad=33, fontsize=15)

# ax1[0].set_title(f"{text}")

text = "she doesn't like it to have"

if ',' in text:
    parts = text.split(',')   # 두 덩이가 된다고 가정
    text = space[0].join(parts)    
else:
    words = text.split()
    num_words = len(words)
    if(num_words > 7): 
        num_words = 7 
    text = space[num_words - 2].join(words)
    

ax1[0].set_title(f"{text}")
#ax1[0].set_ylim(60, 270)
ax1[0].set_ylim(pitch_return[1][0]*0.5, max(pitch_return[1])*1.1)
ax1[0].set_xticks([])
ax1[0].set_yticks([])
for i in range(len(pitch_return[1]) - 1):
    if abs(pitch_return[1][i + 1] - pitch_return[1][i]) <= 25:
        ax1[0].plot(pitch_return[0][i:i + 2], pitch_return[1][i:i + 2],
                 color='blue', linestyle='-', linewidth=3)
    ax1[0].plot(pitch_return[0][i], pitch_return[1][i], color='blue',
             markersize=3)
# plt.savefig("plot1.png",
#             pad_inches=0)


# Original Voice Intensity Plot
ax1[1].set_title(f"                        ")
ax1[1].set_ylim(min(intensity_return[1]), max(intensity_return[1]) * 1.1)
ax1[1].set_xticks([])

ax1[1].set_yticks([])
for i in range(len(intensity_return[1]) - 1):
    if abs(intensity_return[1][i + 1] - intensity_return[1][i]) <= 25:
        ax1[1].plot(intensity_return[0][i:i + 2],
                    intensity_return[1][i:i + 2], color='blue',
                    linestyle='-', linewidth=3)
    ax1[1].plot(intensity_return[0][i], intensity_return[1][i],
                color='blue', markersize=3)
plt.savefig("plot2.png", pad_inches=0)

# TTS Voice Pitch Plot (pitch_return[3])
fig3, ax3 = plt.subplots(2,1, figsize=(10, 4))  # 1행 2열의 서브플롯
ax3[0].set_title(f"                    ")
ax3[0].set_ylim(pitch_return[3][0]*0.5, max(pitch_return[3])*1.1)
ax3[0].set_xticks([])
ax3[0].set_yticks([])
for i in range(len(pitch_return[3]) - 1):
    if abs(pitch_return[3][i + 1] - pitch_return[3][i]) <= 25:
        ax3[0].plot(pitch_return[2][i:i + 2], pitch_return[3][i:i + 2],
                    color='red', linestyle='-', linewidth=3)
    ax3[0].plot(pitch_return[2][i], pitch_return[3][i], color='red',
                markersize=3)
# plt.savefig("plot3.png", pad_inches=0)

# TTS Voice Intensity Plot (intensity_return[3])
ax3[1].set_title(f"                  ")
ax3[1].set_ylim(min(intensity_return[3]), max(intensity_return[3]) * 1.1)
ax3[1].set_xticks([])
ax3[1].set_yticks([])
plt.ylabel('Intensity', rotation=0, labelpad=33, fontsize=15)
ax3[0].set_ylabel('Pitch  ', rotation=0, labelpad=22, fontsize=20)
for i in range(len(intensity_return[3]) - 47):
    if abs(intensity_return[3][i + 1] - intensity_return[3][i]) <= 25:
        ax3[1].plot(intensity_return[2][i:i + 2],
                    intensity_return[3][i:i + 2], color='red',
                    linestyle='-', linewidth=3)
    ax3[1].plot(intensity_return[2][i], intensity_return[3][i],
                color='red', markersize=3)
plt.savefig("plot4.png", pad_inches=0)

# Display all figures
plt.show()

# 이미지 결합
# img1 = Image.open("plot1.png")
# img3 = Image.open("plot3.png")
# blended_img1 = Image.blend(img1, img3, alpha=0.5)
# blended_img1.show()

img2 = Image.open("plot2.png")
img4 = Image.open("plot4.png")
blended_img2 = Image.blend(img2, img4, alpha=0.5)
blended_img2.show()
